import json
import os
import random
import math
from datetime import datetime

import pandas as pd


class MACSManager:
    """ç®¡ç†MACSè®¡ç®—å’Œæ¨¡å‹å‰”é™¤æœºåˆ¶"""

    def __init__(self, enable_removal=False, removal_threshold=0.25,
                 window_size=8, consecutive_windows=2, max_removals=3,
                 use_relative_threshold=True, relative_threshold=0.7,
                 random_removal_prob=0.0, random_removal_mode=False):  # æ–°å¢éšæœºå‰”é™¤å‚æ•°
        """
        åˆå§‹åŒ–MACSç®¡ç†å™¨

        :param enable_removal: æ˜¯å¦å¯ç”¨æ¨¡å‹å‰”é™¤æœºåˆ¶
        :param removal_threshold: ç»å¯¹å‰”é™¤é˜ˆå€¼
        :param window_size: æ»‘åŠ¨çª—å£å¤§å°
        :param consecutive_windows: è¿ç»­è§¦å‘çª—å£æ•°
        :param max_removals: æœ€å¤§å‰”é™¤æ¨¡å‹æ•°
        :param use_relative_threshold: æ˜¯å¦ä½¿ç”¨ç›¸å¯¹é˜ˆå€¼
        :param relative_threshold: ç›¸å¯¹é˜ˆå€¼æ¯”ä¾‹
        :param random_removal_prob: éšæœºå‰”é™¤æ¦‚ç‡ (0.0-1.0)
        :param random_removal_mode: æ˜¯å¦å¯ç”¨çº¯éšæœºå‰”é™¤æ¨¡å¼ (ç¦ç”¨MACSå‰”é™¤)
        """
        self.enable_removal = enable_removal
        self.removal_threshold = removal_threshold
        self.window_size = window_size
        self.consecutive_windows = consecutive_windows
        self.max_removals = max_removals
        self.use_relative_threshold = use_relative_threshold
        self.relative_threshold = relative_threshold
        self.random_removal_prob = random_removal_prob  # éšæœºå‰”é™¤æ¦‚ç‡
        self.random_removal_mode = random_removal_mode  # çº¯éšæœºå‰”é™¤æ¨¡å¼

        # çŠ¶æ€è·Ÿè¸ª
        self.removal_events = []
        self.all_problem_records = []
        self.model_macs_history = {}
        self.removal_count = 0
        self.current_models = []

    def initialize_models(self, model_names):
        """åˆå§‹åŒ–æ¨¡å‹çŠ¶æ€"""
        self.current_models = model_names
        for model_name in model_names:
            if model_name not in self.model_macs_history:
                self.model_macs_history[model_name] = {
                    'scores': [],
                    'low_score_count': 0,
                    'removed': False
                }

    def calculate_macs(self, model_data, selected_word, top_k):
        """
        è®¡ç®—æ¨¡å‹çš„MACSè´¡çŒ®åˆ†æ•°
        :param model_data: æ¨¡å‹æ•°æ®å­—å…¸
        :param selected_word: æœ€ç»ˆé€‰æ‹©çš„token
        :param top_k: è€ƒè™‘çš„top-kæ•°é‡
        """
        # å¤„ç†ç»“æŸç¬¦æ˜ å°„
        target_token = selected_word
        if selected_word == '<end>':
            target_token = model_data['eos_token']

        # åœ¨top-k tokensä¸­æŸ¥æ‰¾ç›®æ ‡token
        found_token = None
        for token_info in model_data['topk_token']:
            if token_info['token'] == target_token:
                found_token = token_info
                break

        # è®¡ç®—logitæŠ•ç¥¨æ”¯æŒåº¦ (c_logit)
        top_tokens = model_data['topk_token']
        if top_tokens:
            max_logprob = top_tokens[0]['logprob']
            eps = 1e-10

            if found_token:
                # ä½¿ç”¨å¯¹æ•°æ¦‚ç‡å·®è®¡ç®—c_logit
                logprob_diff = found_token['logprob'] - max_logprob
                # å°†æ¦‚ç‡å·®è½¬æ¢ä¸º0-1èŒƒå›´çš„åˆ†æ•°
                if logprob_diff >= 0:
                    c_logit = 1.0  # ç›®æ ‡tokenæ˜¯æœ€ä½³token
                else:
                    # ä½¿ç”¨sigmoidè½¬æ¢: èŒƒå›´(-âˆ,0] -> (0,0.5]
                    c_logit = 1 / (1 + math.exp(-logprob_diff))
            else:
                c_logit = 0.0
        else:
            c_logit = 0.0

        # è®¡ç®—Top-Kå‘½ä¸­æƒ…å†µ (c_rank)
        if found_token:
            rank = found_token['token_rank']
            c_rank = (top_k + 1 - rank) / top_k
        else:
            c_rank = 0.0

        # è®¡ç®—æœ€ç»ˆè´¡çŒ®åº¦ (åŠ æƒç»„åˆ)
        alpha = 0.7  # logitåˆ†é‡çš„æƒé‡ (æé«˜é‡è¦æ€§)
        beta = 1 - alpha  # rankåˆ†é‡çš„æƒé‡
        c_total = alpha * c_logit + beta * c_rank

        # å°†åˆ†æ•°æ·»åŠ åˆ°æ¨¡å‹æ•°æ®ä¸­
        model_data['c_logit'] = c_logit
        model_data['c_rank'] = c_rank
        model_data['c_total'] = c_total

        return c_total

    def check_removal_condition(self, current_problem_macs, problem_id, subject):
        """æ£€æŸ¥æ˜¯å¦æ»¡è¶³å‰”é™¤æ¡ä»¶"""
        if not self.enable_removal or self.removal_count >= self.max_removals:
            return None

        models_to_remove = []

        # çº¯éšæœºå‰”é™¤æ¨¡å¼
        if self.random_removal_mode:
            return self.perform_random_removal(problem_id, subject)

        # MACSå‰”é™¤æ¨¡å¼ (å¯èƒ½åŒ…å«éšæœºå‰”é™¤)
        best_model_score = -1

        # é¦–å…ˆè®¡ç®—æœ¬è½®æœ€ä½³æ¨¡å‹åˆ†æ•°ï¼ˆä»…å½“ä½¿ç”¨ç›¸å¯¹é˜ˆå€¼æ—¶ï¼‰
        if self.use_relative_threshold:
            for scores in current_problem_macs.values():
                if scores:
                    avg = sum(scores) / len(scores)
                    if avg > best_model_score:
                        best_model_score = avg

        for model_name, macs_scores in current_problem_macs.items():
            if self.model_macs_history[model_name]['removed']:
                continue

            # è®¡ç®—å½“å‰é—®é¢˜å¹³å‡åˆ†
            current_avg = sum(macs_scores) / len(macs_scores) if macs_scores else 0
            self.model_macs_history[model_name]['scores'].append(current_avg)

            # ç»´æŠ¤çª—å£å¤§å°
            if len(self.model_macs_history[model_name]['scores']) > self.window_size:
                self.model_macs_history[model_name]['scores'].pop(0)

            # æ£€æŸ¥å‰”é™¤æ¡ä»¶
            if len(self.model_macs_history[model_name]['scores']) >= self.consecutive_windows:
                last_n = self.model_macs_history[model_name]['scores'][-self.consecutive_windows:]
                avg_score = sum(last_n) / len(last_n)

                # ç»å¯¹é˜ˆå€¼æ¡ä»¶
                absolute_low = avg_score < self.removal_threshold

                # ç›¸å¯¹é˜ˆå€¼æ¡ä»¶ï¼ˆä»…åœ¨å¯ç”¨æ—¶æ£€æŸ¥ï¼‰
                relative_low = False
                if self.use_relative_threshold and best_model_score > 0:
                    relative_low = avg_score < best_model_score * self.relative_threshold

                # å†³å®šæ˜¯å¦å‰”é™¤
                if absolute_low and (not self.use_relative_threshold or relative_low):
                    # éšæœºå‰”é™¤æ£€æŸ¥ï¼šæœ‰ä¸€å®šæ¦‚ç‡è·³è¿‡MACSå‰”é™¤
                    if self.random_removal_prob > 0 and random.random() > self.random_removal_prob:
                        continue

                    models_to_remove.append(model_name)
                    self.model_macs_history[model_name]['removed'] = True
                    self.removal_count += 1

                    # è®°å½•å‰”é™¤åŸå› 
                    reason = "ç»å¯¹é˜ˆå€¼" if not self.use_relative_threshold else "ç»å¯¹+ç›¸å¯¹é˜ˆå€¼"
                    threshold_info = f"{self.removal_threshold}" if not self.use_relative_threshold else f"{self.removal_threshold} & {best_model_score * self.relative_threshold:.3f}"

                    print(f"ğŸš¨ æ¨¡å‹ {model_name} è¢«å‰”é™¤ | "
                          f"çª—å£å¹³å‡åˆ†: {avg_score:.3f} < é˜ˆå€¼: {threshold_info} "
                          f"(æ¡ä»¶: {reason})")

        # éšæœºå‰”é™¤ï¼ˆåœ¨MACSæ¨¡å¼ä¸­ä½œä¸ºè¡¥å……ï¼‰
        if self.random_removal_prob > 0 and not self.random_removal_mode:
            random_removals = self.perform_random_removal(problem_id, subject)
            if random_removals:
                models_to_remove.extend([r['model_name'] for r in random_removals])

        removal_events = []
        for model_name in models_to_remove:
            event = {
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "subject": subject,
                "problem_id": problem_id,
                "model_name": model_name,
                "window_scores": self.model_macs_history[model_name]['scores'][
                                 -self.consecutive_windows:] if not self.random_removal_mode else [],
                "threshold": self.removal_threshold,
                "relative_threshold_used": self.use_relative_threshold,
                "relative_threshold_value": self.relative_threshold if self.use_relative_threshold else None,
                "best_model_score": best_model_score if self.use_relative_threshold else None,
                "remaining_models": [m for m in self.current_models if m != model_name],
                "removal_type": "random" if self.random_removal_mode or (
                            self.random_removal_prob > 0 and model_name in [r['model_name'] for r in
                                                                            removal_events]) else "MACS"
            }
            self.removal_events.append(event)
            removal_events.append(event)

        return removal_events

    def perform_random_removal(self, problem_id, subject):
        """æ‰§è¡Œéšæœºå‰”é™¤"""
        models_to_remove = []
        removal_events = []

        # è·å–å°šæœªè¢«å‰”é™¤çš„æ¨¡å‹
        available_models = [model for model in self.current_models
                            if not self.model_macs_history[model]['removed']]

        if not available_models:
            return removal_events

        # è®¡ç®—å®é™…å‰”é™¤æ¦‚ç‡ï¼Œè€ƒè™‘æœ€å¤§å‰”é™¤æ•°é‡é™åˆ¶
        effective_prob = min(self.random_removal_prob,
                             (self.max_removals - self.removal_count) / len(available_models))

        for model_name in available_models:
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§å‰”é™¤æ•°é‡
            if self.removal_count >= self.max_removals:
                break

            # æ ¹æ®æ¦‚ç‡å†³å®šæ˜¯å¦å‰”é™¤
            if random.random() < effective_prob:
                self.model_macs_history[model_name]['removed'] = True
                self.removal_count += 1
                models_to_remove.append(model_name)

                print(f"ğŸ² æ¨¡å‹ {model_name} è¢«éšæœºå‰”é™¤ | "
                      f"æ¦‚ç‡: {effective_prob:.2f}")

        for model_name in models_to_remove:
            event = {
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "subject": subject,
                "problem_id": problem_id,
                "model_name": model_name,
                "window_scores": [],
                "threshold": self.random_removal_prob,
                "relative_threshold_used": False,
                "relative_threshold_value": None,
                "best_model_score": None,
                "remaining_models": [m for m in self.current_models if m != model_name],
                "removal_type": "random"
            }
            self.removal_events.append(event)
            removal_events.append(event)

        return removal_events

    def save_removal_records(self, result_dir):
        """ä¿å­˜å‰”é™¤è®°å½•å’Œé—®é¢˜æ•°æ®åˆ°æ–‡ä»¶"""
        if not self.enable_removal:
            return

        # ä¿å­˜å‰”é™¤äº‹ä»¶
        removal_file = os.path.join(result_dir, "removal_events.json")
        with open(removal_file, 'w', encoding='utf-8') as f:
            json.dump(self.removal_events, f, indent=2, ensure_ascii=False)

        # ä¿å­˜æ‰€æœ‰é—®é¢˜è®°å½•åˆ°Excel
        if self.all_problem_records:
            df = pd.DataFrame(self.all_problem_records)

            model_data = []
            for _, row in df.iterrows():
                models = row['models']

                if isinstance(models, list):
                    for model_info in models:
                        model_data.append({
                            "subject": row['subject'],
                            "problem_id": row['problem_id'],
                            "model_name": model_info.get('name', ''),
                            "avg_macs": model_info.get('avg_macs', 0),
                            "scores": json.dumps(model_info.get('scores', [])),
                            "is_correct": row['is_correct'],
                            "accuracy_so_far": row['accuracy_so_far'],
                            "removal_occurred": row['removal_occurred'],
                            "removal_type": row.get('removal_type', 'none')
                        })
                elif isinstance(models, dict):
                    for model_name, model_info in models.items():
                        model_data.append({
                            "subject": row['subject'],
                            "problem_id": row['problem_id'],
                            "model_name": model_name,
                            "avg_macs": model_info.get('avg_macs', 0),
                            "scores": json.dumps(model_info.get('scores', [])),
                            "is_correct": row['is_correct'],
                            "accuracy_so_far": row['accuracy_so_far'],
                            "removal_occurred": row['removal_occurred'],
                            "removal_type": row.get('removal_type', 'none')
                        })
                else:
                    print(f"âš ï¸ æœªçŸ¥çš„modelsç±»å‹: {type(models)}")
                    continue

            model_df = pd.DataFrame(model_data)
            excel_file = os.path.join(result_dir, "all_problems_macs.xlsx")
            model_df.to_excel(excel_file, index=False)

            print(f"ğŸ’¾ ä¿å­˜å‰”é™¤è®°å½• | äº‹ä»¶: {len(self.removal_events)} é—®é¢˜è®°å½•: {len(model_data)}")